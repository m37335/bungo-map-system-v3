#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÔøΩÔøΩ ÈùíÁ©∫ÊñáÂ∫´5‰ΩúÂìÅ‚ÜíÂÆåÂÖ®Âú∞Âêç„Éï„É≠„ÉºÊúÄÁµÇÁâà v4

Âú∞ÂêçÊäΩÂá∫„Ç®„É©„Éº„Çí‰øÆÊ≠£„Åó„ÄÅÊ≠£Á¢∫„Å™Âá¶ÁêÜ„ÇíÂÆüË°å
Áµ±ÂêàÂú∞ÂêçÊäΩÂá∫„ÉªÊ≠£Ë¶èÂåñ„Ç∑„Çπ„ÉÜ„É†„Çí‰ΩøÁî®
"""

import sys
import os
import sqlite3
import requests
import re
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# v4„Éë„Çπ„ÇíËøΩÂä†
sys.path.insert(0, '/app/bungo-map-v4')

# v4„Ç∑„Çπ„ÉÜ„É†„Çí„Ç§„É≥„Éù„Éº„Éà
from src.bungo_map.database.manager import DatabaseManager
from src.bungo_map.extractors_v4.unified_place_extractor import UnifiedPlaceExtractor
from src.bungo_map.extractors_v4.place_normalizer import PlaceNormalizer

# „É≠„Ç¨„Éº„ÅÆË®≠ÂÆö
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FinalWorkflowExecutor:
    """ÊúÄÁµÇÁâàÂÆåÂÖ®„Éï„É≠„ÉºÂÆüË°å„Ç∑„Çπ„ÉÜ„É† v4"""
    
    def __init__(self, db_path: str = '/app/bungo-map-v4/data/databases/bungo_v4.db'):
        self.db_path = db_path
        
        logger.info("üîß ÊúÄÁµÇÁâàÂÆåÂÖ®„Éï„É≠„ÉºÂÆüË°å„Ç∑„Çπ„ÉÜ„É†v4ÂàùÊúüÂåñ‰∏≠...")
        
        # v4„Ç∑„Çπ„ÉÜ„É†ÂàùÊúüÂåñ
        self.db_manager = DatabaseManager(db_path)
        self.unified_extractor = UnifiedPlaceExtractor()
        self.normalizer = PlaceNormalizer()
        
        logger.info("‚úÖ v4Áµ±Âêà„Ç∑„Çπ„ÉÜ„É†ÂàùÊúüÂåñÂÆå‰∫Ü")
    
    def execute_place_extraction_and_geocoding(self):
        """Âú∞ÂêçÊäΩÂá∫„Å®Geocoding„ÅÆÂÆüË°å"""
        logger.info("üöÄ ÊúÄÁµÇÁâàÂú∞ÂêçÊäΩÂá∫+GeocodingÂÆüË°åÈñãÂßã")
        logger.info("=" * 80)
        
        # „Éï„Çß„Éº„Ç∫1: Êó¢Â≠ò„Éá„Éº„Çø„ÅÆÁ¢∫Ë™ç
        logger.info("\nüìä „Éï„Çß„Éº„Ç∫1: Êó¢Â≠ò„Éá„Éº„ÇøÁ¢∫Ë™ç")
        logger.info("-" * 50)
        
        stats = self._get_current_statistics()
        logger.info(f"üë• ‰ΩúÂÆ∂Êï∞: {stats['authors']:,}")
        logger.info(f"üìö ‰ΩúÂìÅÊï∞: {stats['works']:,}")
        logger.info(f"üìù „Çª„É≥„ÉÜ„É≥„ÇπÊï∞: {stats['sentences']:,}")
        logger.info(f"üó∫Ô∏è Êó¢Â≠òÂú∞ÂêçÊï∞: {stats['places']:,}")
        logger.info(f"üîó Êó¢Â≠òÊñá-Âú∞ÂêçÈñ¢‰øÇÊï∞: {stats['sentence_places']:,}")
        
        # „Éï„Çß„Éº„Ç∫2: Âú∞ÂêçÊäΩÂá∫ÂÆüË°å
        logger.info("\nüó∫Ô∏è „Éï„Çß„Éº„Ç∫2: ÂÖ®„Çª„É≥„ÉÜ„É≥„ÇπÂú∞ÂêçÊäΩÂá∫ÂÆüË°å")
        logger.info("-" * 50)
        
        total_extracted = self._extract_all_places()
        logger.info(f"\n‚úÖ „Éï„Çß„Éº„Ç∫2ÂÆå‰∫Ü: {total_extracted}‰ª∂„ÅÆÊñ∞Ë¶èÂú∞ÂêçÊäΩÂá∫")
        
        # „Éï„Çß„Éº„Ç∫3: Áµ±Ë®àÊÉÖÂ†±„ÅÆÊõ¥Êñ∞
        logger.info("\nüìä „Éï„Çß„Éº„Ç∫3: Áµ±Ë®àÊÉÖÂ†±Êõ¥Êñ∞")
        logger.info("-" * 50)
        
        self._update_all_statistics()
        logger.info("\n‚úÖ „Éï„Çß„Éº„Ç∫3ÂÆå‰∫Ü: Áµ±Ë®àÊÉÖÂ†±Êõ¥Êñ∞ÂÆå‰∫Ü")
        
        # ÊúÄÁµÇÁµ±Ë®à
        logger.info("\nüìä „Éï„Çß„Éº„Ç∫4: ÊúÄÁµÇÁµ±Ë®àË°®Á§∫")
        logger.info("-" * 50)
        self._show_comprehensive_statistics()
        
        logger.info(f"\nüéâ ÊúÄÁµÇÁâàÂÆåÂÖ®„Éï„É≠„ÉºÂÆüË°åÂÆå‰∫ÜÔºÅ")
    
    def _get_current_statistics(self) -> Dict[str, int]:
        """ÁèæÂú®„ÅÆÁµ±Ë®àÊÉÖÂ†±ÂèñÂæó"""
        with sqlite3.connect(self.db_path) as conn:
            stats = {}
            
            cursor = conn.execute("SELECT COUNT(*) FROM authors")
            stats['authors'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM works")
            stats['works'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentences")
            stats['sentences'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM places_master")
            stats['places'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentence_places")
            stats['sentence_places'] = cursor.fetchone()[0]
            
            return stats
    
    def _extract_all_places(self) -> int:
        """ÂÖ®„Çª„É≥„ÉÜ„É≥„Çπ„ÅÆÂú∞ÂêçÊäΩÂá∫"""
        total_extracted = 0
        
        try:
            # ÂÖ®„Çª„É≥„ÉÜ„É≥„ÇπÂèñÂæó
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT s.sentence_id, s.sentence_text, s.before_text, s.after_text, s.work_id, s.author_id
                    FROM sentences s
                    WHERE length(s.sentence_text) > 5
                    ORDER BY s.work_id, s.position_in_work
                """)
                all_sentences = cursor.fetchall()
                
                logger.info(f"üìù Âá¶ÁêÜÂØæË±°„Çª„É≥„ÉÜ„É≥„Çπ: {len(all_sentences):,}‰ª∂")
            
            # Âú∞ÂêçÊäΩÂá∫Âá¶ÁêÜ
            for i, (sentence_id, sentence_text, before_text, after_text, work_id, author_id) in enumerate(all_sentences):
                if i > 0 and i % 1000 == 0:
                    logger.info(f"  üìç ÈÄ≤Êçó: {i:,}/{len(all_sentences):,} ({i/len(all_sentences)*100:.1f}%)")
                
                try:
                    # ‰ΩúÂìÅ„ÅÆÂá¶ÁêÜ
                    result = self.db_manager.process_work(
                        work_id=work_id,
                        text=sentence_text,
                        context_before=before_text,
                        context_after=after_text
                    )
                    
                    if result['success']:
                        total_extracted += len(result['saved_places'])
                        
                        if result['saved_places']:
                            place_names = [p['place_name'] for p in result['saved_places']]
                            logger.info(f"    üó∫Ô∏è ÊäΩÂá∫: {', '.join(place_names)}")
                
                except Exception as e:
                    logger.error(f"    ‚ö†Ô∏è „Çª„É≥„ÉÜ„É≥„ÇπÂá¶ÁêÜ„Ç®„É©„Éº: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"‚ùå Âú∞ÂêçÊäΩÂá∫„Ç®„É©„Éº: {e}")
        
        return total_extracted
    
    def _update_all_statistics(self):
        """ÂÖ®Áµ±Ë®àÊÉÖÂ†±„ÅÆÊõ¥Êñ∞"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ‰ΩúÂìÅ„ÅÆÁµ±Ë®àÊõ¥Êñ∞
                cursor = conn.execute("SELECT work_id FROM works")
                work_ids = [row[0] for row in cursor.fetchall()]
                
                for work_id in work_ids:
                    try:
                        stats = self.db_manager.get_work_statistics(work_id)
                        if stats:
                            logger.info(f"  üìö ‰ΩúÂìÅÁµ±Ë®àÊõ¥Êñ∞: {stats['work_title']}")
                            logger.info(f"    Âú∞ÂêçÊï∞: {stats['unique_places']}, Ë®ÄÂèäÂõûÊï∞: {stats['total_mentions']}")
                    except Exception as e:
                        logger.error(f"    ‚ö†Ô∏è ‰ΩúÂìÅÁµ±Ë®àÊõ¥Êñ∞„Ç®„É©„Éº (ID: {work_id}): {e}")
                
                # ‰ΩúËÄÖ„ÅÆÁµ±Ë®àÊõ¥Êñ∞
                cursor = conn.execute("SELECT author_id FROM authors")
                author_ids = [row[0] for row in cursor.fetchall()]
                
                for author_id in author_ids:
                    try:
                        stats = self.db_manager.get_author_statistics(author_id)
                        if stats:
                            logger.info(f"  üë§ ‰ΩúËÄÖÁµ±Ë®àÊõ¥Êñ∞: {stats['author_name']}")
                            logger.info(f"    ‰ΩúÂìÅÊï∞: {stats['work_count']}, Âú∞ÂêçÊï∞: {stats['unique_places']}")
                    except Exception as e:
                        logger.error(f"    ‚ö†Ô∏è ‰ΩúËÄÖÁµ±Ë®àÊõ¥Êñ∞„Ç®„É©„Éº (ID: {author_id}): {e}")
        
        except Exception as e:
            logger.error(f"‚ùå Áµ±Ë®àÊõ¥Êñ∞„Ç®„É©„Éº: {e}")
    
    def _show_comprehensive_statistics(self):
        """ÂåÖÊã¨ÁöÑÁµ±Ë®àË°®Á§∫"""
        with sqlite3.connect(self.db_path) as conn:
            # Âü∫Êú¨Áµ±Ë®à
            final_stats = self._get_current_statistics()
            
            # ‰ΩúÂìÅÂà•Áµ±Ë®à
            cursor = conn.execute("""
                SELECT 
                    a.author_name, w.work_title, w.sentence_count,
                    COUNT(DISTINCT pm.place_id) as unique_places,
                    COUNT(sp.id) as total_mentions
                FROM authors a
                JOIN works w ON a.author_id = w.author_id
                LEFT JOIN sentences s ON w.work_id = s.work_id
                LEFT JOIN sentence_places sp ON s.sentence_id = sp.sentence_id
                LEFT JOIN places_master pm ON sp.place_id = pm.place_id
                GROUP BY a.author_id, w.work_id
                ORDER BY w.created_at DESC
            """)
            work_stats = cursor.fetchall()
            
            # È†ªÂá∫Âú∞ÂêçTOP10
            cursor = conn.execute("""
                SELECT 
                    pm.place_name, 
                    pm.canonical_name,
                    pm.place_type,
                    pm.prefecture,
                    pm.mention_count
                FROM places_master pm
                WHERE pm.mention_count > 0
                ORDER BY pm.mention_count DESC
                LIMIT 10
            """)
            top_places = cursor.fetchall()
        
        logger.info("üìä ÊúÄÁµÇÁµ±Ë®à„É¨„Éù„Éº„Éà")
        logger.info("=" * 60)
        logger.info(f"üë• ‰ΩúÂÆ∂Êï∞: {final_stats['authors']:,}")
        logger.info(f"üìö ‰ΩúÂìÅÊï∞: {final_stats['works']:,}")
        logger.info(f"üìù „Çª„É≥„ÉÜ„É≥„ÇπÊï∞: {final_stats['sentences']:,}")
        logger.info(f"üó∫Ô∏è Á∑èÂú∞ÂêçÊï∞: {final_stats['places']:,}")
        logger.info(f"üîó Êñá-Âú∞ÂêçÈñ¢‰øÇÊï∞: {final_stats['sentence_places']:,}")
        
        logger.info(f"\nüìñ ‰ΩúÂìÅÂà•Âú∞ÂêçÁµ±Ë®à:")
        for author, title, sentences, unique_places, total_mentions in work_stats:
            if unique_places > 0:
                logger.info(f"  ‚Ä¢ {author} - {title}: {unique_places}Âú∞Âêç, {total_mentions}ÂõûË®ÄÂèä")
        
        if top_places:
            logger.info(f"\nüó∫Ô∏è È†ªÂá∫Âú∞ÂêçTOP10:")
            for place_name, canonical_name, place_type, prefecture, count in top_places:
                logger.info(f"  ‚Ä¢ {place_name} ‚Üí {canonical_name}")
                logger.info(f"    „Çø„Ç§„Éó: {place_type}")
                if prefecture:
                    logger.info(f"    ÈÉΩÈÅìÂ∫úÁúå: {prefecture}")
                logger.info(f"    Ë®ÄÂèäÂõûÊï∞: {count}Âõû")


def main():
    """„É°„Ç§„É≥ÂÆüË°åÈñ¢Êï∞"""
    logger.info("üóæ ÊúÄÁµÇÁâàÈùíÁ©∫ÊñáÂ∫´Âú∞ÂêçÊäΩÂá∫+GeocodingÂÆüË°å")
    logger.info("=" * 80)
    
    executor = FinalWorkflowExecutor()
    executor.execute_place_extraction_and_geocoding()


if __name__ == "__main__":
    main() 