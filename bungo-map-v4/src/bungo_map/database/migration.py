"""
Bungo Map System v3.0 to v4.0 Migration

v3.0„ÅÆÂú∞Âêç‰∏≠ÂøÉ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Åã„Çâv4.0„ÅÆ„Çª„É≥„ÉÜ„É≥„Çπ‰∏≠ÂøÉ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Å∏„ÅÆÁßªË°å
"""

import sqlite3
import json
from typing import List, Dict, Any, Optional
from datetime import datetime


class V3ToV4Migrator:
    """v3.0„Åã„Çâv4.0„Å∏„ÅÆÁßªË°å„ÇØ„É©„Çπ"""
    
    def __init__(self, v3_db_path: str, v4_db_path: str):
        self.v3_db_path = v3_db_path
        self.v4_db_path = v4_db_path
        
    def migrate(self) -> bool:
        """ÁßªË°åÂÆüË°å"""
        print("üöÄ v3.0 ‚Üí v4.0 ÁßªË°åÈñãÂßã...")
        
        try:
            # 1. v3.0„Éá„Éº„ÇøË™≠„ÅøËæº„Åø
            v3_data = self._load_v3_data()
            print(f"üìä v3.0„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÂÆå‰∫Ü: {len(v3_data)}‰ª∂")
            
            # 2. „Çª„É≥„ÉÜ„É≥„Çπ„ÉªÂú∞Âêç„ÅÆÂàÜÊûê„ÉªÊ≠£Ë¶èÂåñ
            sentences, places_master = self._analyze_and_normalize(v3_data)
            print(f"üìù „Çª„É≥„ÉÜ„É≥„Çπ: {len(sentences)}‰ª∂„ÄÅÂú∞Âêç„Éû„Çπ„Çø„Éº: {len(places_master)}‰ª∂")
            
            # 3. v4.0„Éá„Éº„Çø„Éô„Éº„Çπ„Å∏„ÅÆÁßªË°å
            self._migrate_to_v4(sentences, places_master)
            print("‚úÖ v4.0ÁßªË°åÂÆå‰∫Ü")
            
            return True
            
        except Exception as e:
            print(f"‚ùå ÁßªË°å„Ç®„É©„Éº: {e}")
            return False
    
    def migrate_limited(self, limit: int) -> bool:
        """Âà∂Èôê‰ªò„ÅçÁßªË°åÂÆüË°å"""
        print(f"üöÄ v3.0 ‚Üí v4.0 Âà∂Èôê‰ªò„ÅçÁßªË°åÈñãÂßã (ÊúÄÂ§ß{limit}‰ª∂)...")
        
        try:
            # 1. v3.0„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÔºàÂà∂Èôê‰ªò„ÅçÔºâ
            v3_data = self._load_v3_data_limited(limit)
            print(f"üìä v3.0„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÂÆå‰∫Ü: {len(v3_data)}‰ª∂")
            
            # 2. „Çª„É≥„ÉÜ„É≥„Çπ„ÉªÂú∞Âêç„ÅÆÂàÜÊûê„ÉªÊ≠£Ë¶èÂåñ
            sentences, places_master = self._analyze_and_normalize(v3_data)
            print(f"üìù „Çª„É≥„ÉÜ„É≥„Çπ: {len(sentences)}‰ª∂„ÄÅÂú∞Âêç„Éû„Çπ„Çø„Éº: {len(places_master)}‰ª∂")
            
            # 3. v4.0„Éá„Éº„Çø„Éô„Éº„Çπ„Å∏„ÅÆÁßªË°å
            self._migrate_to_v4(sentences, places_master)
            print("‚úÖ v4.0Âà∂Èôê‰ªò„ÅçÁßªË°åÂÆå‰∫Ü")
            
            return True
            
        except Exception as e:
            print(f"‚ùå ÁßªË°å„Ç®„É©„Éº: {e}")
            return False
    
    def _load_v3_data(self) -> List[Dict[str, Any]]:
        """v3.0„Éá„Éº„Çø„Éô„Éº„Çπ„Åã„Çâ„Éá„Éº„ÇøË™≠„ÅøËæº„Åø"""
        data = []
        
        with sqlite3.connect(self.v3_db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            cursor = conn.execute("""
                SELECT p.*, w.title as work_title, a.name as author_name
                FROM places p
                LEFT JOIN works w ON p.work_id = w.work_id
                LEFT JOIN authors a ON p.author_id = a.author_id
                WHERE p.sentence IS NOT NULL AND p.sentence != ''
                ORDER BY p.work_id, p.place_id
            """)
            
            for row in cursor.fetchall():
                data.append(dict(row))
        
        return data
    
    def _load_v3_data_limited(self, limit: int) -> List[Dict[str, Any]]:
        """v3.0„Éá„Éº„Çø„Éô„Éº„Çπ„Åã„Çâ„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÔºàÂà∂Èôê‰ªò„ÅçÔºâ"""
        data = []
        
        with sqlite3.connect(self.v3_db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            cursor = conn.execute("""
                SELECT p.*, w.title as work_title, a.name as author_name
                FROM places p
                LEFT JOIN works w ON p.work_id = w.work_id
                LEFT JOIN authors a ON p.author_id = a.author_id
                WHERE p.sentence IS NOT NULL AND p.sentence != ''
                ORDER BY p.work_id, p.place_id
                LIMIT ?
            """, (limit,))
            
            for row in cursor.fetchall():
                data.append(dict(row))
        
        return data
    
    def _analyze_and_normalize(self, v3_data: List[Dict]) -> tuple:
        """v3.0„Éá„Éº„Çø„ÅÆÂàÜÊûê„ÉªÊ≠£Ë¶èÂåñ"""
        sentences_map = {}  # sentence_text -> sentence_info
        places_master_map = {}  # canonical_name -> place_info
        
        for item in v3_data:
            sentence_text = item['sentence']
            place_name = item['place_name']
            
            # „Çª„É≥„ÉÜ„É≥„ÇπÊ≠£Ë¶èÂåñ
            normalized_sentence = self._normalize_sentence(sentence_text)
            
            if normalized_sentence not in sentences_map:
                sentences_map[normalized_sentence] = {
                    'sentence_text': sentence_text,
                    'work_id': item['work_id'],
                    'author_id': item['author_id'],
                    'before_text': item.get('before_text', ''),
                    'after_text': item.get('after_text', ''),
                    'places': [],
                    'source_info': f"v3ÁßªË°å: {item.get('work_title', '')}"
                }
            
            # Âú∞ÂêçÊ≠£Ë¶èÂåñ„Éª„Éû„Çπ„Çø„ÉºÂåñ
            canonical_name = self._normalize_place_name(place_name)
            
            if canonical_name not in places_master_map:
                places_master_map[canonical_name] = {
                    'place_name': place_name,
                    'canonical_name': canonical_name,
                    'aliases': [place_name] if place_name != canonical_name else [],
                    'latitude': item.get('lat'),
                    'longitude': item.get('lng'),
                    'place_type': self._determine_place_type(item.get('extraction_method', '')),
                    'confidence': item.get('confidence', 0.0),
                    'source_system': 'v3.0',
                    'extraction_methods': [item.get('extraction_method', '')]
                }
            else:
                # Âà•ÂêçËøΩÂä†
                existing = places_master_map[canonical_name]
                if place_name not in existing['aliases'] and place_name != existing['place_name']:
                    existing['aliases'].append(place_name)
                
                # ÊäΩÂá∫ÊâãÊ≥ïËøΩÂä†
                method = item.get('extraction_method', '')
                if method and method not in existing['extraction_methods']:
                    existing['extraction_methods'].append(method)
                
                # Â∫ßÊ®ôÊÉÖÂ†±Êõ¥Êñ∞Ôºà„Çà„Çä‰ø°È†ºÂ∫¶„ÅÆÈ´ò„ÅÑ„ÇÇ„ÅÆ„ÇíÂÑ™ÂÖàÔºâ
                if item.get('lat') and item.get('lng'):
                    if (not existing['latitude'] or 
                        item.get('confidence', 0.0) > existing['confidence']):
                        existing['latitude'] = item.get('lat')
                        existing['longitude'] = item.get('lng')
                        existing['confidence'] = item.get('confidence', 0.0)
            
            # „Çª„É≥„ÉÜ„É≥„Çπ-Âú∞ÂêçÈñ¢ÈÄ£ËøΩÂä†
            sentences_map[normalized_sentence]['places'].append({
                'place_name': place_name,
                'canonical_name': canonical_name,
                'extraction_method': item.get('extraction_method', ''),
                'confidence': item.get('confidence', 0.0),
                'matched_text': place_name
            })
        
        return list(sentences_map.values()), list(places_master_map.values())
    
    def _migrate_to_v4(self, sentences: List[Dict], places_master: List[Dict]):
        """v4.0„Éá„Éº„Çø„Éô„Éº„Çπ„Å∏„ÅÆÁßªË°åÂÆüË°å"""
        with sqlite3.connect(self.v4_db_path) as conn:
            # 1. Âú∞Âêç„Éû„Çπ„Çø„ÉºÊåøÂÖ•
            place_id_map = {}  # canonical_name -> place_id
            
            for place in places_master:
                cursor = conn.execute("""
                    INSERT INTO places_master (
                        place_name, canonical_name, aliases, latitude, longitude,
                        place_type, confidence, source_system, verification_status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    place['place_name'],
                    place['canonical_name'],
                    json.dumps(place['aliases'], ensure_ascii=False),
                    place['latitude'],
                    place['longitude'],
                    place['place_type'],
                    place['confidence'],
                    place['source_system'],
                    'verified'  # v3.0„Åã„Çâ„ÅÆÁßªË°å„ÅØÊ§úË®ºÊ∏à„Åø„Å®„Åô„Çã
                ))
                
                place_id_map[place['canonical_name']] = cursor.lastrowid
            
            # 2. „Çª„É≥„ÉÜ„É≥„ÇπÊåøÂÖ•
            for sentence in sentences:
                cursor = conn.execute("""
                    INSERT INTO sentences (
                        sentence_text, work_id, author_id, before_text, after_text, source_info
                    ) VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    sentence['sentence_text'],
                    sentence['work_id'],
                    sentence['author_id'],
                    sentence['before_text'],
                    sentence['after_text'],
                    sentence['source_info']
                ))
                
                sentence_id = cursor.lastrowid
                
                # 3. „Çª„É≥„ÉÜ„É≥„Çπ-Âú∞ÂêçÈñ¢ÈÄ£ÊåøÂÖ•
                for place_info in sentence['places']:
                    canonical_name = place_info['canonical_name']
                    place_id = place_id_map.get(canonical_name)
                    
                    if place_id:
                        conn.execute("""
                            INSERT INTO sentence_places (
                                sentence_id, place_id, extraction_method, confidence,
                                matched_text, verification_status
                            ) VALUES (?, ?, ?, ?, ?, ?)
                        """, (
                            sentence_id,
                            place_id,
                            place_info['extraction_method'],
                            place_info['confidence'],
                            place_info['matched_text'],
                            'migrated'
                        ))
            
            conn.commit()
    
    def _normalize_sentence(self, sentence: str) -> str:
        """„Çª„É≥„ÉÜ„É≥„ÇπÊ≠£Ë¶èÂåñ"""
        if not sentence:
            return ""
        
        # Á©∫ÁôΩ„ÉªÊîπË°å„ÅÆÁµ±‰∏Ä
        normalized = sentence.strip()
        normalized = normalized.replace('\n', ' ').replace('\r', ' ')
        normalized = ' '.join(normalized.split())  # ÈÄ£Á∂öÁ©∫ÁôΩ„Çí1„Å§„Å´
        
        return normalized
    
    def _normalize_place_name(self, place_name: str) -> str:
        """Âú∞ÂêçÊ≠£Ë¶èÂåñ"""
        if not place_name:
            return ""
        
        normalized = place_name.strip()
        
        # „Çà„Åè„ÅÇ„ÇãË°®Ë®òÊè∫„ÇåÁµ±‰∏Ä
        normalized = normalized.replace('„É∂', '„Åå')
        normalized = normalized.replace('„Ç±', '„Åå')
        normalized = normalized.replace('„ÄÄ', ' ')
        
        return normalized
    
    def _determine_place_type(self, extraction_method: str) -> str:
        """ÊäΩÂá∫ÊâãÊ≥ï„Åã„ÇâÂú∞Âêç„Çø„Ç§„Éó„ÇíÊ±∫ÂÆö"""
        if 'regex_ÈÉΩÈÅìÂ∫úÁúå' in extraction_method:
            return 'ÈÉΩÈÅìÂ∫úÁúå'
        elif 'regex_Â∏ÇÂå∫Áî∫Êùë' in extraction_method:
            return 'Â∏ÇÂå∫Áî∫Êùë'
        elif 'regex_ÈÉ°' in extraction_method:
            return 'ÈÉ°'
        elif 'regex_ÊúâÂêçÂú∞Âêç' in extraction_method:
            return 'ÊúâÂêçÂú∞Âêç'
        else:
            return 'ÊúâÂêçÂú∞Âêç'  # „Éá„Éï„Ç©„É´„Éà
    
    def get_migration_summary(self) -> Dict[str, Any]:
        """ÁßªË°åÁµêÊûú„Çµ„Éû„É™„Éº"""
        try:
            with sqlite3.connect(self.v4_db_path) as conn:
                conn.row_factory = sqlite3.Row
                
                # Áµ±Ë®àÂèñÂæó
                cursor = conn.execute("SELECT * FROM statistics_summary")
                stats = dict(cursor.fetchone()) if cursor.fetchone() else {}
                
                # v3.0Áî±Êù•„Éá„Éº„Çø
                cursor = conn.execute(
                    "SELECT COUNT(*) as count FROM places_master WHERE source_system = 'v3.0'"
                )
                v3_places = cursor.fetchone()['count']
                
                cursor = conn.execute(
                    "SELECT COUNT(*) as count FROM sentence_places WHERE verification_status = 'migrated'"
                )
                v3_relations = cursor.fetchone()['count']
                
                return {
                    'total_sentences': stats.get('total_sentences', 0),
                    'total_places': stats.get('total_places', 0),
                    'total_relations': stats.get('total_relations', 0),
                    'v3_migrated_places': v3_places,
                    'v3_migrated_relations': v3_relations,
                    'migration_date': datetime.now().isoformat()
                }
                
        except Exception as e:
            return {'error': str(e)} 