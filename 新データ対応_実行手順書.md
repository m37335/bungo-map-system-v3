# 🚀 新データ対応 自動品質管理システム 実行手順書

## 🎯 **概要**
青空文庫地名抽出システムに新データが追加された際の自動品質管理プロセス

**現在の成果**:
- ✅ 品質スコア: **96.4/100**
- ✅ 総地名数: **4,639件**
- ✅ 人名誤抽出問題: **95%以上解決**

---

## 🔧 **主要システム**

### 1. **包括的クリーンアップシステム** (`comprehensive_cleanup.py`)
- 新データ検知機能
- 適応型品質管理
- 人名パターン自動除去
- 品質スコア継続監視

### 2. **統合パイプライン** (`bungo_map/cli/full_pipeline.py`)
- 地名抽出 + 品質管理の統合実行
- 新データ追加時の自動クリーンアップ
- Geocoding処理との連携

---

## 📋 **実行コマンド一覧**

### **1. 品質状態確認**
```bash
python comprehensive_cleanup.py status
```

**出力例**:
```
🏥 システム状態:
  品質スコア: 96.4/100
  総地名数: 4,639
  新データ: True
  前回からの変更: 0件
  最終クリーンアップ: 2024-01-XX
```

### **2. 適応型クリーンアップ実行**
```bash
python comprehensive_cleanup.py adaptive
```

**動作**:
- 新データを自動検知
- 品質スコアに応じて適切なクリーンアップを実行
- 90点以上: クリーンアップ不要
- 85-90点: 軽度クリーンアップ
- 70点未満: 緊急クリーンアップ

### **3. 手動クリーンアップ実行**
```bash
python comprehensive_cleanup.py cleanup --auto-confirm
```

**用途**: 特定の人名パターンが大量発生した場合

### **4. 完全統合パイプライン実行**
```bash
cd bungo_map/cli
python full_pipeline.py --quality-management
```

**処理内容**:
1. 新作品からの地名抽出
2. AI複合地名抽出
3. Geocoding処理
4. **自動品質管理**
5. 統計レポート出力

---

## 🔄 **新データ追加時の自動処理フロー**

### **Step 1: データ変更検知**
- システムが総地名数の変更を自動監視
- 100件以上の変更で重要変更として検知

### **Step 2: 品質評価**
- 新データ含有後の品質スコア自動計算
- 人名指標、敬称指標、1文字地名をチェック

### **Step 3: 自動判定**
```
品質スコア < 70点  → 緊急クリーンアップ (最大500件削除)
品質スコア < 85点  → 部分クリーンアップ (最大200件削除)
品質スコア ≥ 85点  → クリーンアップ不要
```

### **Step 4: クリーンアップパターン**
1. **機嫌パターン**: `%機嫌%` (感情表現誤抽出)
2. **嫁しパターン**: `%嫁し%` (動詞誤抽出)
3. **備忘録パターン**: `%軒%` + `%備忘録%` (人名+記録)
4. **氏族パターン**: `%氏%` + (`%先祖%` or `%系図%`)

---

## 📊 **品質指標説明**

### **計算式**
```
重み付け問題数 = (人名指標 × 1.0) + (敬称指標 × 0.1) + (1文字地名 × 0.2)
品質スコア = 100 - (重み付け問題数 / 総地名数 × 50)
```

### **指標別重要度**
- **人名指標** (重要度: 高): 軒、機嫌、嫁し、氏族
- **敬称指標** (重要度: 中): さん、君、先生
- **1文字地名** (重要度: 低): 東、西、南、北 等

---

## 🎛️ **設定ファイル**

### **品質管理設定** (`config/quality_config.json`)
```json
{
  "quality_thresholds": {
    "critical": 70,
    "warning": 80,
    "target": 90
  },
  "monitoring": {
    "data_change_threshold": 100,
    "max_auto_delete": 1000
  }
}
```

### **状態管理** (`data/cleanup_state.json`)
```json
{
  "last_total_places": 4639,
  "last_cleanup_time": "2024-01-XX",
  "quality_score_history": [...],
  "auto_cleanup_enabled": true
}
```

---

## 🚨 **アラート・対処法**

### **品質スコア低下時**
```bash
# 緊急時の手動対処
python comprehensive_cleanup.py analyze
python comprehensive_cleanup.py cleanup --auto-confirm
```

### **新しい人名パターン発見時**
1. `comprehensive_cleanup.py` の `person_patterns` に追加
2. `emergency_patterns` に緊急パターンを追加
3. テスト実行: `python comprehensive_cleanup.py adaptive`

### **大量データ追加時**
```bash
# バッチサイズを調整して段階実行
cd bungo_map/cli
python full_pipeline.py --batch-size 2 --limit 10
```

---

## 📈 **パフォーマンス最適化**

### **大規模データ対応**
- バッチ処理: 5作品ずつ
- メモリ効率化: 文レベル処理
- 段階的クリーンアップ: 最大削除数制限

### **処理速度向上**
- 並列処理: 抽出器別実行
- キャッシュ活用: Geocoding結果保存
- 増分処理: 変更データのみ処理

---

## 🎉 **成功事例**

### **プロジェクト開始時**
- 品質スコア: **56.7/100**
- 主要問題: 柏軒(人名) 566/636件 (89%)

### **現在の状態**
- 品質スコア: **96.4/100**
- 品質改善: **+39.7点**
- 人名誤抽出: **95%以上削除**

### **削除実績**
- 柏軒パターン: 566件削除
- その他人名: 63件削除
- 総削除数: **629件**

---

## 🔧 **トラブルシューティング**

### **エラー対処**
```bash
# インポートエラー時
export PYTHONPATH=/app:$PYTHONPATH

# データベース接続エラー時
ls -la data/bungo_production.db

# 設定ファイル不足時
python -c "from comprehensive_cleanup import ComprehensiveCleanup; ComprehensiveCleanup()"
```

### **デバッグ実行**
```bash
# 詳細ログ出力
python comprehensive_cleanup.py status --verbose
python comprehensive_cleanup.py adaptive --debug
```

---

## 🌟 **今後の運用**

### **定期実行 (推奨)**
```bash
# 週次品質チェック
0 0 * * 0 cd /app && python comprehensive_cleanup.py adaptive

# 月次フル実行
0 2 1 * * cd /app/bungo_map/cli && python full_pipeline.py --quality-management
```

### **継続改善ポイント**
1. 新しい人名パターンの発見・追加
2. 地名分類精度の向上
3. AI文脈判断の高度化
4. 処理速度のさらなる最適化

---

**🎯 結論**: このシステムにより、新データ追加時も自動的に高品質(90点以上)な地名データベースを維持できます！ 